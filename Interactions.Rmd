---
title: "Workflow for Multi-Table Differential Correlation Analysis"
output: html_document
author: Christof Seiler
date: "`r Sys.Date()`"
params:
  seed: "2"
  res_file: "res_2.Rdata"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goal

The goal of this `Rmd` document is to load registration results and cognitive tests into `R`, tidy the data, perform exploratory analysis, and use our new `R` package `braincog` to find brain-cognition differential correlations in girls with Turner syndrome and age-matched healthy controls.

## Input Parameters

```{r params}
params
```

## Packages

Package `SimpleITK` needs to be installed prior to running this `Rmd` file because it takes a couple of hours to compile. For details on the installation process and pre-compiled packages, please refer to our instructions on [GitHub](https://github.com/ChristofSeiler/braincog).

```{r install_packges, warning=FALSE, message=FALSE}
pkgs_needed = c("ChristofSeiler/braincog",
                "tibble","magrittr","dplyr","devtools","readr","stringr",
                "PMA","genefilter","BiocParallel",
                "ggfortify","EBImage","mice","abind","factoextra",
                "visdat","ggbeeswarm","GGally")
letsinstall = setdiff(pkgs_needed, installed.packages()) 
if (length(letsinstall) > 0) {
  source("http://bioconductor.org/biocLite.R")
  biocLite(letsinstall)
}
```

Once all package have been installed, we are ready to load them.

```{r load_packages, warning=FALSE, message=FALSE}
library("braincog")
library("SimpleITK")
library("tibble")
library("magrittr")
library("dplyr")
library("devtools")
library("readr")
library("stringr")
library("PMA")
library("genefilter")
library("BiocParallel")
library("ggfortify")
library("EBImage")
library("mice")
library("abind")
library("factoextra")
library("visdat")
library("ggbeeswarm")
library("GGally")
theme_set(theme_grey())
```

## Load Non-Imaging Data

The patient and behavioral data was saved in two separate text files. However these files are linked with an subject ID, which is internal ID at the Center for Interdisciplinary Brain Sciences Research (CIBSR) at Stanford School of Medicine.

```{r read_csv}
cognition = read_csv("TURNER_DATA_all_import_tg.csv")
sample_info = read_csv("TURNER_DATA_8_3_final.csv")
```

Combined both data frames into one, remove unnecessary variables, and defined column types. We have size domains:

* Attention and Executive Functioning (AEF)
* Language (L)
* Memory and Learning (ML)
* Sensorimotor (S)
* Social Perception (SP)
* Visuospatial Processing (VP)

```{r formating}
cognition %<>% dplyr::rename(ID = 'CIBSR ID (Subject ID Generated by FilemakerPro and Timepoint)')
cognition = left_join(cognition,sample_info,by = "ID")
cognition$ID %<>% formatC(format = "f",digits = 1)
```

## Load Imaging Data

Load template and mask images.

```{r read_mean}
template_arr = ReadImage("Mean.nii.gz") %>% as.array
```

Plotting function for one slice using `EBImage` package.

```{r plot_mean}
plot_slice(template_arr,axis = 1)
plot_slice(template_arr,axis = 2)
plot_slice(template_arr,axis = 3)
```

Mask out all the non-gray matter tissue.

```{r read_gray_matter}
label_arr = ReadImage("Gray.Matter.nii.gz") %>% as.array
# for debugguing select one region
#regions = ReadImage("FSL.Atlas.Cort.To.Mean.nii.gz") %>% as.array
#label_arr[regions != 1] = 0
plot_slice(label_arr)
```

Load Jacobian determinant images.

```{r read_morphometry}
filenames = list.files(pattern = ".1.Ants.LogJacDet.nii.gz")
jac_list = lapply(filenames,function(filename) {
  print(filename)
  brain = ReadImage(filename)
  gray_matter = as.array(brain)[label_arr != 0]
  tibble(gray_matter)
})
morphometry = jac_list %>% bind_cols %>% t
rownames(morphometry) = substr(filenames,1,7)
```

## Handle Missing Data

Remove some columns in `cognition` that are not important in this study.

```{r tidy_cognition}
cognition %<>% dplyr::rename('Quality' = 'DATA quality structural')
cognition$Quality %<>% factor
cognition %<>% select(-`Redcap ID`)
cognition %<>% select(-`Please choose one`)
cognition %<>% select(-`Please choose one_1`)
cognition %<>% select(-`Age (at consent)`)
cognition %<>% select(-`DATA quality HARDI`)
cognition %<>% select(-`Group`)
cognition$Diagnosis %<>% factor
cognition$Sex %<>% factor
cognition$POO %<>% factor
names(cognition)
```

Now we need to handle the missing values in the NEPSY subtest scores.

```{r plot_missingness, fig.width=9,fig.height=9}
vis_dat(cognition) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0))
vis_miss(cognition) +
  theme(axis.text.x = element_text(angle = 90, hjust = 0))
```

Exclude subjects and subtests that have more than the preset threshold of missing values.

```{r exclude}
exclude_thres = 0.2
# check variables
nna = apply(cognition,2,function(column) mean(is.na(column)))
exclude_cols = nna > exclude_thres
sum(exclude_cols)
which(exclude_cols)
if(sum(exclude_cols) > 0) 
  cognition = cognition[,-which(exclude_cols)]
# check subjects
nna = apply(cognition,1,function(row) mean(is.na(row)))
exclude_rows = nna > exclude_thres
sum(exclude_rows)
if(sum(exclude_rows)) 
  cognition = cognition[-which(exclude_rows),]
sum(is.na(cognition))/prod(dim(cognition))
```

```{r plot_exclude, fig.width=9,fig.height=9}
vis_dat(cognition) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 0))
vis_miss(cognition) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 0))
```

Run data imputation method predictive mean matching `pmm`.

```{r impute}
cognition_subset = cognition %>% select(-ID) %>% select(-Diagnosis) %>% select(-Sex)
num_imp = 20
res_mice = mice(cognition_subset,method = "pmm",
                m = num_imp,
                maxit = 20,
                seed = as.integer(params$seed),
                printFlag = FALSE)
# take the mean over all imputed data sets
cognition_imp = lapply(seq_len(num_imp),function(i) complete(res_mice, i)) %>% 
  abind(along = 3) %>%
  apply(MARGIN = c(1,2),FUN = mean) %>%
  as.tibble
# fix the data frame
names(cognition_imp) = names(cognition_subset)
cognition_imp %<>% add_column(ID = cognition$ID,
                              Diagnosis = cognition$Diagnosis,
                              Sex = cognition$Sex)
```

Match patient IDs in `cognition_imp` and `morphometry` tables. Make sure that the rows are ordered in the same way.

```{r match}
inter_id = intersect(rownames(morphometry),cognition_imp$ID)
cognition_imp = cognition_imp[sapply(inter_id,function(ID) which(cognition_imp$ID == ID)),]
morphometry = morphometry[sapply(inter_id,function(ID) which(rownames(morphometry) == ID)),]
```

Save output for next data analysis step.

```{r save}
save(cognition_imp,file = "cognition_imp.Rdata")
save(morphometry,file = "morphometry.Rdata")
```

## Summary

After data preparation, we end up with the following sample size.

```{r summary}
summize_data = function(cognition) {
  cognition %>% dplyr::group_by(Diagnosis) %>% dplyr::summarize(
    n = length(ID),
    FSIQ_mean = mean(`FSIQ Composite Score`,na.rm = TRUE),
    FSIQ_sd = sd(`FSIQ Composite Score`,na.rm = TRUE),
    FSIQ_min = min(`FSIQ Composite Score`,na.rm = TRUE),
    FSIQ_max = max(`FSIQ Composite Score`,na.rm = TRUE),
    arrows_mean = mean(`Arrows Total Score Scaled Score`,na.rm = TRUE),
    arrows_sd = sd(`Arrows Total Score Scaled Score`,na.rm = TRUE),
    age_mean = mean(Age,na.rm = TRUE),
    age_sd = sd(Age,na.rm = TRUE),
    age_min = min(Age,na.rm = TRUE),
    age_max = max(Age,na.rm = TRUE)) %>%
    mutate_if(is.numeric, funs(round(., 1))) %>% 
    print(width = Inf)
}
summize_data(cognition)
summize_data(cognition_imp)
```

Do a two-sample nonparametric test for age, a chi-squared test of homogeneity for Tanner stages to check if the two groups are age matched.

```{r tests}
# test of shift in location
with(cognition_imp,
     wilcox.test(Age[Diagnosis=="Monosomic Turner"],
                 Age[Diagnosis=="Control"]))
# test of scale
with(cognition_imp,
     mood.test(Age[Diagnosis=="Monosomic Turner"],
               Age[Diagnosis=="Control"]))
with(cognition_imp,
     ansari.test(Age[Diagnosis=="Monosomic Turner"],
                 Age[Diagnosis=="Control"]))
# test of homogeneity
with(cognition,table(Diagnosis,Breast))
with(cognition,table(Diagnosis,Pubic))
combined = tibble(Diagnosis = c(cognition$Diagnosis,cognition$Diagnosis),
                  Tanner = c(cognition$Breast,cognition$Pubic))
# not enough observations at Turner stage 3 to 5, so merge them
ct = table(combined)
ct
ct_merge = tibble(tanner_1 = ct[,1],tanner_2 = ct[,2],tanner_345 = rowSums(ct[,3:5]))
ct_merge
chisq.test(ct_merge)
```

## Data Exploration and Quality Control

Prepare cognition data. Mapping test to domain.

```{r prepare_cognition}
shorter_col_names = function(col_names) {
  col_names %>% str_replace("Scaled","") %>% 
    str_replace("Score","") %>% 
    str_replace("Score","") %>% 
    str_replace("Combined","") %>% 
    str_replace("Total","") %>% 
    str_replace("Contrast","") %>%
    trimws %>%
    gsub(pattern = "\\.",replacement = "") %>%
    str_replace("-"," ") %>%
    lapply(function(col_name) 
      str_split(string = col_name,pattern = " ")[[1]] %>% paste(collapse = "_")) %>%
    str_replace("__","_")
}
cognition_scores_only = cognition_imp %>% select(ends_with("Scaled Score")) 
names(cognition_scores_only) %<>% shorter_col_names
domain_mapping = tibble(
  test = names(cognition_scores_only),
  domain = c(
    rep("Attention and Executive Functioning",7),
    rep("Language",5),
    rep("Memory and Languageearning",5),
    rep("Sensorimotor",8),
    rep("Visuospatial Processing",2)
  )
)
iq_scores_only = cognition_imp[,c("VCI Composite Score",
                                  "PRI Composite Score",
                                  "WMI Composite Score",
                                  "PSI Composite Score")]
```

PCA plot for cognition.

```{r cog_pca}
data = cognition_imp %>% dplyr::rename(FSIQ = 'FSIQ Composite Score')
res_pca_cognition = prcomp(cognition_scores_only,center = TRUE, scale. = TRUE)
fviz_eig(res_pca_cognition,geom="bar")
explained_var = (100*res_pca_cognition$sdev^2/sum(res_pca_cognition$sdev^2)) %>% round(.,1)
autoplot(res_pca_cognition,
         size = 3,
         data = data,
         colour = "FSIQ",
         shape = "Diagnosis",
         xlab = paste0("PC1 (",explained_var[1],"%)"),
         ylab = paste0("PC2 (",explained_var[2],"%)")) +
  coord_fixed(ratio = explained_var[2] / explained_var[1]) +
  ggtitle("Cognitive Tests")
ggplot2::ggsave(filename = "cognition_pca.pdf",width = 8,height = 3)
```

Plot loadings of the first cognition principal component.

```{r cog_loadings}
cog_load = domain_mapping %>% add_column(loadings = res_pca_cognition$rotation[,1])
cog_load$test = factor(cog_load$test, levels = domain_mapping$test)
ggplot(cog_load,aes(x = loadings,y = test,color = domain)) + 
  geom_point(size = 3) + 
  geom_vline(xintercept = 0) +
  ggtitle("Cognition Loadings")
ggplot2::ggsave(filename = "cognition_loadings.pdf",width = 8,height = 5)
```

PCA plot for morphometry.

```{r brain_pca}
plot_morphometry_pca = function(res_pca_morphometry,sample_info) {
  explained_var = (100*res_pca_morphometry$sdev^2/sum(res_pca_morphometry$sdev^2)) %>% round(.,1)
  autoplot(res_pca_morphometry,
           size = 3,
           data = sample_info,
           colour = "FSIQ",
           shape = "Diagnosis",
           xlab = paste0("PC1 (",explained_var[1],"%)"),
           ylab = paste0("PC2 (",explained_var[2],"%)")) +
    coord_fixed(ratio = explained_var[2] / explained_var[1]) + 
    ggtitle("Brain Morphometry")
}
sample_info = cognition_imp %>% dplyr::rename(FSIQ = 'FSIQ Composite Score')
res_pca_morphometry = prcomp(morphometry,center = TRUE, scale. = TRUE)
fviz_eig(res_pca_morphometry,geom="bar")
plot_morphometry_pca(res_pca_morphometry,sample_info)
# # remove potential outlier
# potential_outlier = which.max(abs(res_pca_morphometry$x[,2]))
# res_pca_morphometry = prcomp(morphometry[-potential_outlier,],scale. = FALSE)
# fviz_eig(res_pca_morphometry,geom="bar")
# plot_morphometry_pca(res_pca_morphometry,sample_info[-potential_outlier,])
ggplot2::ggsave(filename = "morphometry_pca.pdf",width = 6,height = 4)
```

Plot loadings of the first morphometry principal component.

```{r brain_loadings}
loadings_to_arr = function(loadings,axis = 3,probs = 0.2) {
  
  # color quantiles
  loadings = morphometry_loadings
  qs = quantile(loadings,probs = c(probs/2,1-probs/2))
  loadings_sign = rep("white",length(loadings))
  loadings_sign[loadings >= qs[1] & loadings <= qs[2]] = "darkgray"
  loadings_sign[loadings < qs[1]] = "blue"
  loadings_sign[loadings > qs[2]] = "red"
  loadings_arr = array("white",dim = dim(label_arr))
  loadings_arr[label_arr != 0] = loadings_sign
  loadings_arr
}
morphometry_loadings = res_pca_morphometry$rotation[,1]
ggplot(tibble(morphometry_loadings),aes(x = morphometry_loadings)) + 
  geom_histogram(bins = 100)
morphometry_loadings_arr = loadings_to_arr(morphometry_loadings)
combine_slices(morphometry_loadings_arr,
               center_color = "darkgray",
               crop = 15,
               title = "Morphometry Loadings")
ggplot2::ggsave(filename = "morphometry_loadings.pdf",width = 5,height = 5)
```

Test interaction.

```{r test_interaction}
tb_score = tibble(Diagnosis = cognition_imp$Diagnosis,
                  FSIQ = cognition_imp$`FSIQ Composite Score`,
                  Cognition = res_pca_cognition$x[,1],
                  Morphometry = res_pca_morphometry$x[,1])
ggplot(tb_score,aes(y = Cognition,x = Morphometry,color = FSIQ,shape = Diagnosis)) + 
  geom_point(size = 3) +
  ggtitle("Morphometry-Cognition Correlation")
ggplot(tb_score,aes(y = Cognition,x = Morphometry,color = Diagnosis)) + 
  stat_smooth(method = "lm", se = FALSE, mapping = aes(color = Diagnosis)) +
  geom_point(size = 3) +
  ggtitle("Morphometry-Cognition Correlation")
model1 = lm(formula = Cognition ~ Morphometry,data = tb_score)
summary(model1)
model2 = lm(formula = Cognition ~ Morphometry + Diagnosis,data = tb_score)
summary(model2)
model3 = lm(formula = Cognition ~ Morphometry * Diagnosis,data = tb_score)
summary(model3)
anova(model1,model2)
anova(model2,model3)
```

Alternatively analysis by separating groups and testing correlation.

```{r}
score_ts = tb_score %>% 
  filter(Diagnosis == "Monosomic Turner") %>% 
  .[,c("Cognition","Morphometry")] %>%
  scale(center = TRUE,scale = TRUE)
ggplot(score_ts,aes(y = Cognition,x = Morphometry)) +
  stat_smooth(method = "lm", se = FALSE) +
  geom_point(size = 3) +
  ggtitle("Morphometry-Cognition for Monosomic Turner") +
  coord_fixed()
score_control = tb_score %>% 
  filter(Diagnosis == "Control") %>% 
  .[,c("Cognition","Morphometry")] %>%
  scale(center = TRUE,scale = TRUE)
ggplot(score_control,aes(y = Cognition,x = Morphometry)) +
  stat_smooth(method = "lm", se = FALSE) +
  geom_point(size = 3) +
  ggtitle("Morphometry-Cognition for Control") +
  coord_fixed()
cor(score_ts)["Cognition","Morphometry"]
cor(score_control)["Cognition","Morphometry"]
```

## Correlations of Cogntive Tests

Let's look at the pairwise correlations. We see that Visuomotor Precision Completation is negatively correlated to most other tests.

```{r cog_corr}
ggcorr(cognition_scores_only)
```

## Filtering via Hypothesis Testing

Use testing to select voxels and cognitive tests that are different between TS and controls.

Cognition:

```{r cog_colttests}
alpha = 0.05
res_ttests = colttests(x = as.matrix(cognition_scores_only),
                      fac = cognition_imp$Diagnosis)
cog_sel = res_ttests$p.value %>% p.adjust(method = "BH") < alpha
mean(cog_sel)
rownames(res_ttests)[cog_sel]
```

Morphometry:

```{r brain_colttests}
alpha = 0.05
res_ttests = colttests(x = morphometry, 
                      fac = cognition_imp$Diagnosis)
morph_sel = res_ttests$p.value %>% p.adjust(method = "BH") < alpha
mean(morph_sel)
plot_filter = function(morph_sel,axis = 3) {
  filter_arr = array("white",dim = dim(label_arr))
  filter_arr[label_arr != 0] = morph_filtered_vec = ifelse(morph_sel,
                                                           no = "darkgray",
                                                           yes = "red")
  array_dims = lapply(1:3,function(i) seq_len(dim(filter_arr)[i]))
  array_dims[[axis]] = round(dim(filter_arr)[axis]/2)
  slice = filter_arr[array_dims[[1]],array_dims[[2]],array_dims[[3]]] %>% 
    flip %>% 
    flop
  display(EBImage::Image(slice),method = "raster",interpolate = FALSE)
}
plot_filter(morph_sel,axis = 1)
plot_filter(morph_sel,axis = 2)
plot_filter(morph_sel,axis = 3)
```

## Multi-Table Differential Correlation Analysis

Load cortical atlas to define minimum detectable cluster size.

```{r min_clustersize}
cortical_atlas_arr = ReadImage("FSL.Atlas.Cort.To.Mean.nii.gz") %>% as.array
plot_slice(cortical_atlas_arr)
min_clustersize = min(table(cortical_atlas_arr))/2
min_clustersize
```

Finally, we are ready to do a brain cognition differential correlation analysis.

```{r braincog, warning=FALSE, message=FALSE}
# fac: (n x 1) factor with two levels
# morphometry: (n x num_voxels) matrix
# cognition: (n x num_tests) matrix
# gray_matter: binary image
res = NULL
if(!file.exists(params$res_file)) {
  res = braincog(fac = cognition_imp$Diagnosis,
                 morphometry = scale(morphometry,center = TRUE,scale = FALSE),
                 cognition = scale(cognition_scores_only,center = TRUE,scale = FALSE),
                 gray_matter = label_arr,
                 min_clustersize = min_clustersize,
                 num_perm = 1000,
                 slurm = TRUE,
                 seed = 0xdada)
  save(res,file = paste0("res_",params$seed,".Rdata"))
} else {
  load(params$res_file)
}
summary(res)
selected_clusters = summary(res) %>% 
  dplyr::filter(pvalue_adj <= 0.05)
for(cluster_id in selected_clusters$id) {
  plot(res,cluster_id) %>% print
  ggplot2::ggsave(filename = paste0("cluster_",cluster_id,".pdf"),width = 5,height = 5)
}
for(cluster_id in selected_clusters$id)
  plot_statistic(res,cluster_id) %>% print
```

Plot results for cognition.

```{r plot_cognition, fig.width=10, fig.height=5}
plot_cognition(res,domain_mapping,alpha = 0.01)
ggsave(filename = "CognitiveCoefficients.pdf",width = 10,height = 5)
```

Pairs plot to visualize correlations in original data on only selected brain clusters and cognitive tests.

```{r braincog_selection}
# selection at some significance level alpha
selected_tests = summary_cognition(res) %>% 
  dplyr::filter(pvalue_adj <= 0.01)
selected_tests %<>% filter(test != "Diagnosis")
selected_clusters = summary(res) %>% 
  dplyr::filter(pvalue_adj <= 0.05)
# compute cluster size for each participant
seg = res$seg
gray_matter = res$gray_matter
seg_gray_matter = seg[gray_matter==1]
brain_selection = apply(selected_clusters,1,function(cluster) {
  tb = morphometry[,seg_gray_matter==cluster["label"]] %>% 
    exp %>% 
    rowSums %>% 
    tibble
  names(tb) = paste0("Cluster_",cluster["id"])
  tb
}) %>% bind_cols
cog_selection = cognition_scores_only[,selected_tests$test]
```

Plot raw cluster size data points.

```{r brain_beeswarm, fig.width=6,fig.height=2.5}
if(length(brain_selection) > 0) {
  brain_selection_long = reshape2::melt(brain_selection %>% 
                                          add_column(diagnosis = cognition_imp$Diagnosis), 
                                        id.vars = "diagnosis")
  p = ggplot(brain_selection_long,aes(x = variable,y = value, color = diagnosis)) + 
    geom_beeswarm(cex = 4) +
    ylab("cluster size") +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank()) +
    facet_wrap(~ str_replace(variable,"_"," "),scales = "free_x")
  print(p)
  ggplot2::ggsave(filename = "selected_brain_cluster_size.pdf",width = 6,height = 2.5)
}
```

Plot raw cognitive test data points.

```{r cog_stat_ecdf, fig.width=10,fig.height=5}
break_line = function(long_test_names) {
  long_test_names %>% 
  as.character %>% 
  str_split(pattern = "_") %>%
  .[[1]] %>%
  paste0(collapse = " ") %>% 
  str_wrap(width = 20)
}
if(length(cog_selection) > 0) {
  cog_selection_long = reshape2::melt(cog_selection %>% 
                                        add_column(diagnosis = cognition_imp$Diagnosis), 
                                      id.vars = "diagnosis")
  cog_selection_long %<>% mutate(test_with_linebreak = sapply(variable,break_line))
  p = ggplot(cog_selection_long,aes(x = value, color = diagnosis)) + 
    stat_ecdf() + 
    facet_wrap(~test_with_linebreak,ncol = 7) + 
    xlab("test score") +
    theme(axis.title.y = element_blank()) +
    theme(legend.position="top")
  print(p)
  ggplot2::ggsave(filename = "selected_cognition_score.pdf",width = 10,height = 5)
}
```

Plot raw correlation data between clusters and cognitive tests.

```{r joint_braincog, fig.width=10,fig.height=6}
if(length(brain_selection) > 0 & length(cog_selection) > 0) {
  for(i in seq_len(ncol(brain_selection))) {
    brain_column = brain_selection[,i]
    column_name = names(brain_column)
    clustercog_selection = bind_cols(brain_column,
                                     cog_selection,
                                     diagnosis = cognition_imp$Diagnosis)
    clustercog_selection_long = reshape2::melt(clustercog_selection, 
                                             id.vars = c(column_name,"diagnosis"))
    clustercog_selection_long %<>% mutate(test_with_linebreak = sapply(variable,break_line))
    p = ggplot(clustercog_selection_long,
           aes_string(x = column_name,y = "value",color = "diagnosis")) +
      geom_point(alpha = 0.5) +
      stat_smooth(method = "lm", se = FALSE, mapping = aes(color = diagnosis)) +
      facet_wrap(~test_with_linebreak,ncol = 7) +
      ggtitle(str_replace(column_name,"_"," ")) +
      xlab("cluster size") +
      ylab("test score") +
      theme(legend.position="top")
    print(p)
    ggplot2::ggsave(plot = p, filename = paste0("pair_brain_cognition_",column_name,".pdf"),
                    width = 10,height = 6)
  }
}
```

## R Session Information

```{r session_info}
session_info()
```
